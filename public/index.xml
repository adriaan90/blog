<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Adriaan&#39;s blog</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Adriaan&#39;s blog</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 28 Jun 2018 00:00:00 +0100</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Adriaan&#39;s blog</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Understanding Thermodynamics</title>
      <link>/project2/understanding-thermodynamics/</link>
      <pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/project2/understanding-thermodynamics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ideal Rankine Cycle with feedwater heater calculations</title>
      <link>/post/ideal-rankine-cycle-with-regen/</link>
      <pubDate>Sat, 02 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/ideal-rankine-cycle-with-regen/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The content of this post is based on the video:&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/pWCvllVFNHQ&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;div style=&#34;text-align: left;&#34;&gt;

&lt;div id=&#34;the-problem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The problem&lt;/h3&gt;
&lt;p&gt;Consider a regenerative cycle using steam as the working fluid. Steam leaves the boiler and enters the turbine at 4 MPa, 400&lt;span class=&#34;math inline&#34;&gt;\(^\circ\)&lt;/span&gt;C. After expansion to 400 kPa, some of the steam is extracted from the turbine to heat the feedwater in an open FWH. The pressure in the FWH is 400 kPa, and the water leaving it is saturated liquid at 400 kPa. The steam not extracted expands to 10 kPa. Determine the cycle efficiency.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/Ideal-Rankine-Cycle-with-regen/index_files/Rankine-cycle-regen.PNG&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looking at the mass flow of steam entering and exiting the turbine:
&lt;span class=&#34;math display&#34;&gt;\[y = \dot{m}_6/\dot{m}_5\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and thus &lt;span class=&#34;math inline&#34;&gt;\(\dot{m}_6\)&lt;/span&gt; can be written as a function of &lt;span class=&#34;math inline&#34;&gt;\(\dot{m}_5\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\dot{m}_6 = y\dot{m}_5\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Similarly &lt;span class=&#34;math inline&#34;&gt;\(\dot{m}_7\)&lt;/span&gt; can be written as:
&lt;span class=&#34;math display&#34;&gt;\[\dot{m}_7=(1-y)\dot{m}_5\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and
&lt;span class=&#34;math display&#34;&gt;\[\dot{m}_7=(1-y)\dot{m}_5=\dot{m}_1=\dot{m}_2\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;initiate-pyromat-and-configure-its-units&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Initiate &lt;em&gt;PYroMat&lt;/em&gt; and configure its units:&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pyromat as pm
import numpy as np

pm.config[&amp;quot;unit_pressure&amp;quot;] = &amp;quot;kPa&amp;quot;
pm.config[&amp;quot;def_p&amp;quot;] = 100

mp_water = pm.get(&amp;quot;mp.H2O&amp;quot;) # &amp;lt;-- for multi-phase water properties&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To solve this problem we consider a control surface around the pump, the boiler, the turbine, and the condenser.&lt;/p&gt;
&lt;p&gt;First, let us consider the &lt;strong&gt;low pressure pump&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;p1 = 10 # &amp;lt;-- given
p2 = 400 # &amp;lt;-- given

v1 = 1/mp_water.ds(p=p1)[0]

w_pump1 = v1*(p2-p1)
h2 = h1+w_pump1
print(f&amp;quot;Work required by pump 1: {round(float(w_pump1),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Work required by pump 1: 0.4 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, let’s consider &lt;strong&gt;the turbine&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;p5 = 4000 # &amp;lt;-- given
T5 = 400+273.15 # K &amp;lt;-- given
h5 = mp_water.h(p=p5, T=T5)
s5 = mp_water.s(p=p5, T=T5)

s6 =s5
p6 = 400 # &amp;lt;-- given
T6, x6 = mp_water.T_s(s=s6, p=p6, quality=True)
h6 = mp_water.h(x=x6, p=p6)

print(f&amp;quot;Quality of bled steam: {round(float(x6),4)}&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Quality of bled steam: 0.9757&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s consider the &lt;strong&gt;feedwater heater&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;p3 = 400 # &amp;lt;-- given
h3 = mp_water.hs(p=p3)[0]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The energy conservation equation for the FWH is: &lt;span class=&#34;math display&#34;&gt;\[y(h_6)+(1-y)h_2 = h_3\]&lt;/span&gt;
This can be re-arranged to solve &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; explicitly: &lt;span class=&#34;math display&#34;&gt;\[y = \frac{h_2 - h_3}{h_2 - h_6}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;y = (h2-h3)/(h2-h6)
print(f&amp;quot;y = {round(float(y),4)}&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;y = 0.1654&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now calculate the work extracted by the turbine:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;p7 = p1
s7 = s5
T7, x7 = mp_water.T_s(s=s7, p=p7, quality=True)
h7 = mp_water.h(x=x7, p=p7)
w_t = h5 - y*h6 - (1-y)*h7
print(f&amp;quot;Work generated by turbine: {round(float(w_t),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Work generated by turbine: 980.4 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, let’s consider the high pressure pump:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;p4 = 4000 # &amp;lt;-- given
v3 = 1/mp_water.ds(p=p3)[0]
w_pump2 = v3*(p4-p3)
print(f&amp;quot;Work required by pump 2: {round(float(w_pump2),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Work required by pump 2: 3.9 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can consider the &lt;strong&gt;boiler&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;h4 = h3 + w_pump2
q_H = h5-h4
print(f&amp;quot;Heat input by boiler: {round(float(q_H),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Heat input by boiler: 2605.9 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now calculate the thermal efficiency with &lt;span class=&#34;math display&#34;&gt;\[\eta_{th}=\frac{w_{net}}{q_H}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;eta_th = (w_t - w_pump1*(1-y) - w_pump2)/q_H*100
print(f&amp;quot;Thermal efficiency is: {round(float(eta_th),2)}%&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Thermal efficiency is: 37.46%&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Ideal Rankine Cycle with reheat calculations</title>
      <link>/post/ideal-rankine-cycle-with-reheat/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/ideal-rankine-cycle-with-reheat/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The content of this post is based on the video:&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/qGvLk6XqcVQ&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;div style=&#34;text-align: left;&#34;&gt;

&lt;div id=&#34;the-problem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The problem&lt;/h3&gt;
&lt;p&gt;Consider a reheat cycle utilizing steam. Steam leaves the boiler and enters the turbine at 4 MPa, 400&lt;span class=&#34;math inline&#34;&gt;\(^\circ\)&lt;/span&gt;C. After expansion in the turbine to 400 kPa, the steam is reheated to 400&lt;span class=&#34;math inline&#34;&gt;\(^\circ\)&lt;/span&gt;C and then expanded in the low-pressure turbine to 10 kPa. Determine the cycle efficiency.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/Ideal-Rankine-Cycle-with-reheat/index_files/Rankine-cycle-reheat.PNG&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;initiate-pyromat-and-configure-its-units&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Initiate &lt;em&gt;PYroMat&lt;/em&gt; and configure its units:&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pyromat as pm

pm.config[&amp;quot;unit_pressure&amp;quot;] = &amp;quot;kPa&amp;quot;
pm.config[&amp;quot;def_p&amp;quot;] = 100

mp_water = pm.get(&amp;quot;mp.H2O&amp;quot;) # &amp;lt;-- for multi-phase water properties&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To solve this problem we consider a control surface around the pump, the boiler, the turbine, and the condenser.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-pump&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The pump&lt;/h3&gt;
&lt;p&gt;First, consider the pump:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#saturated liquid, thus x = 0
p1 = 10
s1 = mp_water.ss(p=p1)[0]
T1 = mp_water.Ts(p=p1)[0]

p2 = 4000
s2 = s1
T2 = mp_water.T_h(h=h2,p=p2)

h2dash = mp_water.hs(p=p2)[0]
s2dash = mp_water.ss(p=p2)[0]
T2dash = mp_water.Ts(p=p2)[0]

h3dash = mp_water.hs(p=p2)[1]
s3dash = mp_water.ss(p=p2)[1]
T3dash = T2dash

v = 1/mp_water.ds(p=p1)[0]

w_p = v*(p2-p1)

print(f&amp;quot;Specific volume: {round(float(v),5)} m^3/kg&amp;quot;)
print(f&amp;quot;Work required by pump: {round(float(w_p),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Specific volume: 0.00101 m^3/kg
Work required by pump: 4.0 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;h1 = mp_water.hs(p=p1)[0]
h2 = h1+w_p
print(f&amp;quot;h2 = {round(float(h2),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;h2 = 195.8 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-hp-turbine&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The HP turbine&lt;/h3&gt;
&lt;p&gt;Next, let’s consider the high pressure turbine:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;p3 = p2
T3 = 400 + 273.15
h3 = mp_water.h(p=p3, T=T3)
s3 = mp_water.s(p=p3, T=T3)

p4 = 400
s4 = s3
T4, x4 = mp_water.T_s(s=s4, p=p4, quality=True)
h4 = mp_water.h(x=x4, p=p4)

w_HPt = h3-h4

print(f&amp;quot;Quality of intermediate pressure steam: {round(float(x4),4)}&amp;quot;)
print(f&amp;quot;Work generated by HP turbine: {round(float(w_HPt),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Quality of intermediate pressure steam: 0.9757
Work generated by HP turbine: 528.2 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-lp-turbine&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The LP turbine&lt;/h3&gt;
&lt;p&gt;Now, we consider the low pressure turbine:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;p5 = p4
T5 = 400 + 273.15 
h5 = mp_water.h(p=p5, T=T5)
s5 = mp_water.s(p=p5, T=T5)

p6 = p1
s6 = s5

T6, x6 = mp_water.T_s(s=s6, p=p6, quality=True)
h6 = mp_water.h(x=x6, p=p6)

w_LPt = h5-h6

print(f&amp;quot;Quality of low pressure steam: {round(float(x6),4)}&amp;quot;)
print(f&amp;quot;Work generated by LP turbine: {round(float(w_LPt),1)} kJ/kg&amp;quot;)
print(f&amp;quot;Total work output by turbine: {round(float(w_HPt+w_LPt),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Quality of low pressure steam: 0.9669
Work generated by LP turbine: 769.3 kJ/kg
Total work output by turbine: 1297.5 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-boiler&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The boiler&lt;/h3&gt;
&lt;p&gt;Next, let’s consider the boiler:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;q_H = (h3-h2)+(h5-h4)
print(f&amp;quot;Heat input by boiler: {round(float(q_H),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Heat input by boiler: 3606.2 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-condenser&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The condenser&lt;/h3&gt;
&lt;p&gt;Finally, we consider the condenser:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;q_L = h6-h1
print(f&amp;quot;Heat rejected by the condenser: {round(float(q_L),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Heat rejected by the condenser: 2312.8 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;calculating-the-thermal-efficiency&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calculating the thermal efficiency&lt;/h3&gt;
&lt;p&gt;We can now calculate the thermal efficiency with &lt;span class=&#34;math display&#34;&gt;\[\eta_{th}=\frac{w_{net}}{q_H}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;eta_th = (w_HPt+w_LPt-w_p)/q_H*100
print(f&amp;quot;Thermal efficiency is: {round(float(eta_th),1)}%&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Thermal efficiency is: 35.9%&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-rankine-cycle-on-a-graph&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Rankine cycle on a graph&lt;/h3&gt;
&lt;p&gt;Once all the values have been calculated, the ideal Rankine Cycle can be shown visually with the use of a graph.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import numpy as np
import matplotlib.pyplot as plt

p = np.linspace(1,22063,1000)
T = mp_water.Ts(p=p)
s = mp_water.ss(p=p)


font = {&amp;#39;family&amp;#39; : &amp;#39;Times New Roman&amp;#39;,
        &amp;#39;size&amp;#39;   : 22}


plt.figure(figsize=(15,10))
plt.title(&amp;#39;Ideal Rankine Cycle T-s Diagram&amp;#39;)
plt.rc(&amp;#39;font&amp;#39;, **font)
plt.plot(s[0],T, &amp;#39;b--&amp;#39;)
plt.plot(s[1],T,&amp;#39;r--&amp;#39;)
plt.ylabel(&amp;#39;Temperature (K)&amp;#39;)
plt.xlabel(&amp;#39;Entropy (s)&amp;#39;)
plt.xlim(-2,10)
#plt.ylim(200,800)
plt.plot([s1, s2, s2dash, s3dash, s3, s4, s5, s6, s1],[T1, T2, T2dash, T3dash, T3, T4, T5, T6, T1], &amp;#39;black&amp;#39;)

plt.text(s1-.1,T1,f&amp;#39;(1)\nT = {round(float(T1),2)} K\nh = {round(float(h1),1)} kJ/kg\n s = {round(float(s1),3)} kJ/kgK&amp;#39;,
    ha=&amp;#39;right&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
plt.text(1.6,330,f&amp;#39;(2)\nT = {round(float(T2),2)} K\nh = {round(float(h2),1)} kJ/kg&amp;#39;,
    ha=&amp;#39;left&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
plt.text(s2dash-.15,T2dash,f&amp;quot;(2&amp;#39;)\nT = {round(float(T2dash),2)} K\nh = {round(float(h2dash),1)} kJ/kg \ns = {round(float(s2dash),3)} kJ/kgK&amp;quot;,
    ha=&amp;#39;right&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
plt.text(s3dash-.1,T3dash-60,f&amp;quot;(3&amp;#39;)\nh = {round(float(h3dash),1)} kJ/kg \ns = {round(float(s3dash),3)} kJ/kgK&amp;quot;,
    ha=&amp;#39;right&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
plt.text(6.3,T3-50,f&amp;#39;(3)\nT = {round(float(T3),2)} K\nh = {round(float(h3),1)} kJ/kg&amp;#39;,
    ha=&amp;#39;right&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
plt.text(s4-.1,T4-80,f&amp;#39;(4)\nT = {round(float(T4),2)} K\nh = {round(float(h4),1)} kJ/kg \ns = {round(float(s4),3)} kJ/kgK\nx = {round(float(x4),3)}&amp;#39;,
    ha=&amp;#39;right&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
plt.text(s5+.1,T5-70,f&amp;#39;(5)\nT = {round(float(T4),2)} K\nh = {round(float(h4),1)} kJ/kg \ns = {round(float(s4),3)} kJ/kgK&amp;#39;,
    ha=&amp;#39;left&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
plt.text(s6+.1,T6,f&amp;#39;(6)\nT = {round(float(T4),2)} K\nh = {round(float(h4),1)} kJ/kg \nx = {round(float(x6),3)}&amp;#39;,
    ha=&amp;#39;left&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Ideal-Rankine-Cycle-with-reheat/index_files/output_18_1.png&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Ideal Rankine Cycle calculations</title>
      <link>/post/ideal-rankine-cycle/</link>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/ideal-rankine-cycle/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The content of this post is based on the video:&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/U4t1CBDMlmg&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;div style=&#34;text-align: left;&#34;&gt;

&lt;div id=&#34;the-problem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The problem&lt;/h3&gt;
&lt;p&gt;Consider the following question:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Determine the efficiency of a Rankine cycle using steam as the working fluid in which the condenser pressure is 10 kPa. The boiler pressure is 2 MPa. The steam leaves the boiler as saturated vapor.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/Ideal-Rankine-Cycle/index_files/Rankine-cycle-reheat.PNG&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;initiate-pyromat-and-configure-its-units&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Initiate &lt;em&gt;PYroMat&lt;/em&gt; and configure its units:&lt;/h3&gt;
&lt;p&gt;The first thing that we need to do before we start with solving the problem, is to import the necessary packages and configure PYroMat to use the correct units:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pyromat as pm

pm.config[&amp;quot;unit_pressure&amp;quot;] = &amp;quot;kPa&amp;quot;
pm.config[&amp;quot;def_p&amp;quot;] = 100

mp_water = pm.get(&amp;quot;mp.H2O&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To determine the cycle efficiency, we must calculate the turbine work, the pump work, and the heat transfer to the steam in the boiler. We do this by considering a control surface around each of these components in turn. In each case the thermodynamic model is the steam tables, and the process is steady state with negligible changes in kinetic and potential energies.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-pump&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The pump&lt;/h3&gt;
&lt;p&gt;First, consider the pump:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#saturated liquid, thus x = 0
p1 = 10 # &amp;lt;--given
T1 = mp_water.Ts(p=p1)[0]
s1 = mp_water.ss(p=p1)[0]
p2 = 2000 # &amp;lt;--given and converted to kPa
s2= s1
v = 1/mp_water.ds(p=p1)[0]

w_p = v*(p2-p1)
print(f&amp;quot;Work required by pump: {round(float(w_p),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Work required by pump: 2.0 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the work required by the pump is calculated, the enthalpy value after the pump (point 2) can be calculated:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;h1 = mp_water.hs(p=p1)[0]
h2 = h1+w_p
T2 = mp_water.T_h(p=p2,h=h2)

print(f&amp;quot;h2 = {round(float(h2),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;h2 = 193.8 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-boiler&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The boiler&lt;/h3&gt;
&lt;p&gt;Next, lets consider the boiler:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# steam leaves the boiler as saturated vapor, thus x = 1
p3 = p2
T3 = mp_water.Ts(p=p3)

h3 = mp_water.hs(p=p3)[1]
s3dash = mp_water.ss(p=p3)[0]
T3dash = T3
s3 = mp_water.ss(p=p3)[1]
q_H = h3-h2

print(f&amp;quot;Heat input by boiler: {round(float(q_H),1)} kJ/kg&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Heat input by boiler: 2604.5 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-turbine&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The turbine&lt;/h3&gt;
&lt;p&gt;Now, we consider the turbine:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;p4 = p1
s4 = s3
T4, x = mp_water.T_s(s=s4,p=p4, quality=True)
h4 = mp_water.h(p=p4,x=x)
w_t = h3-h4
print(f&amp;quot;Quality of low pressure steam: {round(float(x),4)}&amp;quot;)
print(f&amp;quot;Work generated by turbine: {round(float(w_t),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Quality of low pressure steam: 0.7587
Work generated by turbine: 791.7 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-condenser&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The condenser&lt;/h3&gt;
&lt;p&gt;Finally, we consider the condenser:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;q_L = h4-h1
print(f&amp;quot;Heat rejected by the condenser: {round(float(q_L),1)} kJ/kg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Heat rejected by the condenser: 1814.8 kJ/kg&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;thermal-efficiency&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Thermal efficiency&lt;/h3&gt;
&lt;p&gt;We can now calculate the thermal efficiency with &lt;span class=&#34;math display&#34;&gt;\[\eta_{th}=\frac{w_{net}}{q_H}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;eta_th = (w_t-w_p)/q_H*100
print(f&amp;quot;Thermal efficiency is: {round(float(eta_th),1)}%&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;cmd&#34;&gt;&lt;code&gt;Thermal efficiency is: 30.3%&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-the-ideal-rankine-cycle&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Plotting the Ideal Rankine Cycle&lt;/h3&gt;
&lt;p&gt;After all the points have been calculated, the Rankine Cycle can be shown visually on a graph.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import numpy as np
import matplotlib.pyplot as plt

p = np.linspace(1,22063,1000)
T = mp_water.Ts(p=p)
s = mp_water.ss(p=p)


font = {&amp;#39;family&amp;#39; : &amp;#39;Times New Roman&amp;#39;,
        &amp;#39;size&amp;#39;   : 22}


plt.figure(figsize=(15,10))
plt.title(&amp;#39;Ideal Rankine Cycle T-s Diagram&amp;#39;)
plt.rc(&amp;#39;font&amp;#39;, **font)
plt.plot(s[0],T, &amp;#39;b--&amp;#39;)
plt.plot(s[1],T,&amp;#39;r--&amp;#39;)
plt.ylabel(&amp;#39;Temperature (K)&amp;#39;)
plt.xlabel(&amp;#39;Entropy (s)&amp;#39;)
plt.plot([s1, s2, s3dash, s3, s4, s1],[T1, T2, T3dash, T3, T4, T1], &amp;#39;black&amp;#39;)

plt.text(s1-.1,T1,f&amp;#39;(1)\nT = {round(float(T1),2)} K\nh = {round(float(h1),1)} kJ/kg\n s = {round(float(s1),3)} kJ/kgK&amp;#39;,
    ha=&amp;#39;right&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
plt.text(1.6,330,f&amp;#39;(2)\nT = {round(float(T2),2)} K\nh = {round(float(h2),1)} kJ/kg \ns = {round(float(s2),3)} kJ/kgK&amp;#39;,
    ha=&amp;#39;left&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
plt.text(s3+.1,T3,f&amp;#39;(3)\nT = {round(float(T3),2)} K\nh = {round(float(h3),1)} kJ/kg \ns = {round(float(s3),3)} kJ/kgK&amp;#39;,
    ha=&amp;#39;left&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
plt.text(s4+.1,T4,f&amp;#39;(4)\nT = {round(float(T4),2)} K\nh = {round(float(h4),1)} kJ/kg \ns = {round(float(s4),3)} kJ/kgK\nx = {round(float(x),3)}&amp;#39;,
    ha=&amp;#39;left&amp;#39;,backgroundcolor=&amp;#39;white&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Ideal-Rankine-Cycle/index_files/output_16_1.png&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Web scraping Facebook</title>
      <link>/project/web-scrape-facebook/</link>
      <pubDate>Mon, 06 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/project/web-scrape-facebook/</guid>
      <description>&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#the-data-source&#34;&gt;The data source&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#coding-the-web-scraper&#34;&gt;Coding the web scraper&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#get-the-html-data&#34;&gt;Get the HTML data&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#zooming-in&#34;&gt;Zooming in&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#people-who-shared&#34;&gt;People who shared&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#people-who-follows-your-page&#34;&gt;People who follows your page&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#determine-the-winner&#34;&gt;Determine the winner&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This coding project is building on 
&lt;a href=&#34;https://www.adriaansblog.com/project/web-scrape-coronavirus/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;my first web scraping project&lt;/a&gt; and uses some of the code I developed in that project to get the data from Facebook.
I am sure you have seen posts from a company&amp;rsquo;s or small business&amp;rsquo;s Facebook page where they ask you to like, share and follow in order to win a prize. 
But, how do these businesses then determine who have won? They will have to go and compare the names of all the people who:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;liked the post,&lt;/li&gt;
&lt;li&gt;shared the post and&lt;/li&gt;
&lt;li&gt;followed their page&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and then randomly select a winner from that group of people. If there are about 10 people who engaged with that promotional post, then it won&amp;rsquo;t take too long, but imagine if hundreds of people participated? It will take quite a lot of time to determine the winner then&amp;hellip;&lt;/p&gt;
&lt;p&gt;To help save a bit of time, we are going to construct a program that will scrape all the names of the people who engaged with the promotion post and randomly select a winner from the eligible participants.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Right! Let&amp;rsquo;s get started!&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-data-source&#34;&gt;The data source&lt;/h2&gt;
&lt;p&gt;We are interested in the names of people who follow the business&amp;rsquo;s page and who liked and shared the post in question. All of this information is available on Facebook. In the end we will have three lists:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a list containing the names of people who follow the business&amp;rsquo;s Facebook page,&lt;/li&gt;
&lt;li&gt;a list of people who have liked the promotional post and&lt;/li&gt;
&lt;li&gt;a list of people who have shared the post.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The names that appear in all three lists, will be put in a final list and a random winner will be selected from the list of eligible names.&lt;/p&gt;
&lt;h2 id=&#34;coding-the-web-scraper&#34;&gt;Coding the web scraper&lt;/h2&gt;
&lt;h3 id=&#34;requirements&#34;&gt;Requirements&lt;/h3&gt;
&lt;p&gt;For this program to work, you will need to install:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.7&lt;/li&gt;
&lt;li&gt;Requests library&lt;/li&gt;
&lt;li&gt;Beautifulsoup library&lt;/li&gt;
&lt;li&gt;Selenium library&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;get-the-html-data&#34;&gt;Get the HTML data&lt;/h3&gt;
&lt;p&gt;First thing we need to do is to get the HTML data of the Facebook post we are interested in, into our Python script. We can do this using the Python library, &lt;code&gt;requests&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Web scraping Facebook is a bit different, as the content is behind a login page. We will need to first have a look at the HTML code of the login page. For this project, we are going to log into &lt;a href=&#34;https://mbasic.facebook.com&#34;&gt;https://mbasic.facebook.com&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;start working your way through the HTML until you find the &lt;code&gt;&amp;lt;form&amp;gt;&lt;/code&gt; HTML tag.&lt;/li&gt;
&lt;li&gt;within the &lt;code&gt;&amp;lt;form&amp;gt;&lt;/code&gt; tag look for the &lt;code&gt;method=&amp;quot;post&amp;quot;&lt;/code&gt; argument.&lt;/li&gt;
&lt;li&gt;go down further into the form tag and look for the &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt; tags. There should be at least two (&lt;code&gt;username&lt;/code&gt; and &lt;code&gt;password&lt;/code&gt;). The username input tag is generally of &lt;code&gt;type=email&lt;/code&gt; and the password, &lt;code&gt;type=password&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;look within these input tags for a name argument. This is the name of this input field. This is also how requests is going to know where to “enter” your credentials. For this it is &lt;code&gt;name=&amp;quot;email&amp;quot;&lt;/code&gt; and &lt;code&gt;name=&amp;quot;pass&amp;quot;&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;log-into-facebook&#34;&gt;Log into Facebook&lt;/h4&gt;
&lt;p&gt;The following code can be used to log into your Facebook account in order to scrape the necessary data that we need:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;LOGIN_URL = &#39;https://www.facebook.com/login&#39;

payload = {
  &#39;email&#39;: &#39;your username&#39;,
  &#39;pass&#39;: &#39;your password&#39;
}

with requests.Session() as session:
  post = session.post(LOGIN_URL, data=payload)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;scrape-the-data&#34;&gt;Scrape the data&lt;/h4&gt;
&lt;p&gt;The URL is standard for most posts. You will need the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ID of post&lt;/li&gt;
&lt;li&gt;amount of people who engaged with the post&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the two variables known, the URL where we will scrape the data is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;REQUEST_URL = f&#39;https://mbasic.facebook.com/ufi/reaction/profile/
browser/fetch/?limit={limit}&amp;amp;total_count=17&amp;amp;ft_ent_identifier={post_ID}&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can scrape the data by adding the following line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;with requests.Session() as session:
  post = session.post(POST_LOGIN_URL, data=payload)
  
  r = session.get(REQUEST_URL) #Add this line
  #^^^ Add this line... ^^^
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;zooming-in&#34;&gt;Zooming in&lt;/h3&gt;
&lt;p&gt;With the HTML data stored in the variable &lt;code&gt;r&lt;/code&gt; we can get the names of the people who liked the post with the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;soup = BeautifulSoup(r.content, &amp;quot;html.parser&amp;quot;)
names = soup.find_all(&#39;h3&#39;, class_=&#39;be&#39;)
people_who_liked = []
for name in names:
  people_who_liked.append(name.text)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The list &lt;code&gt;people_who_liked&lt;/code&gt; has been created can will be used later.&lt;/p&gt;
&lt;h2 id=&#34;people-who-shared&#34;&gt;People who shared&lt;/h2&gt;
&lt;p&gt;The same can be done for getting the list of people who shared the post, with a few changes to the code for &lt;code&gt;BeautifulSoup&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;with requests.Session() as session:
  post = session.post(POST_LOGIN_URL, data=payload)
  r = session.get(REQUEST_URL)
  
soup = BeautifulSoup(r.content, &amp;quot;html.parser&amp;quot;)
names = soup.find_all(&#39;span&#39;)

people_who_shared = []
for name in names:
  people_who_shared.append(name.text)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;people-who-follows-your-page&#34;&gt;People who follows your page&lt;/h2&gt;
&lt;p&gt;This one is a bit more tricky. We can only access the list of people who follows a page, if you have administrator rights to that pages. Also, the list is not shown when you access it through the website address &lt;a href=&#34;https://mbasic.facebook.com&#34;&gt;https://mbasic.facebook.com&lt;/a&gt; and &lt;a href=&#34;https://m.facebook.com&#34;&gt;https://m.facebook.com&lt;/a&gt; and we will thus need another approach to get the HTML data through the use of the Selenium library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Log in to Facebook&lt;/li&gt;
&lt;li&gt;Navigate to page settings listing the people who liked our page&lt;/li&gt;
&lt;li&gt;Scroll down until all the names are displayed on the screen&lt;/li&gt;
&lt;li&gt;Scrape the list of names&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;load-the-page-of-names&#34;&gt;Load the page of names&lt;/h4&gt;
&lt;p&gt;Selenium can take control of the browser and log in:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options

webdriver.driver.get(&amp;quot;https://www.facebook.com/login&amp;quot;)

sleep(2)

email_in = webdriver.driver.find_element_by_xpath(&#39;//*[@id=&amp;quot;email&amp;quot;]&#39;)
email_in.send_keys(username)

password_in = webdriver.driver.find_element_by_xpath(&#39;//*[@id=&amp;quot;pass&amp;quot;]&#39;)
password_in.send_keys(password)

login_btn = webdriver.driver.find_element_by_xpath(&#39;//*[@id=&amp;quot;loginbutton&amp;quot;]&#39;)
login_btn.click()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;sleep()&lt;/code&gt; command gives the page time to load before entering the login details. Next we navigate to the page settings listing all the names:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;page_name = your-page-name
REQUEST_URL = f&#39;https://www.facebook.com/{page_name}/settings/
?tab=people_and_other_pages&amp;amp;ref=page_edit&#39;

webdriver.driver.get(REQUEST_URL)

sleep(2)
scrolls = 15

for i in range(1,scrolls):
  webdriver.driver.execute_script(&amp;quot;window.scrollTo(0, document.body.scrollHeight);&amp;quot;)
  sleep(3)

  page = webdriver.driver.page_source
  soup = BeautifulSoup(page, &amp;quot;html.parser&amp;quot;)
  names = soup.find_all(&#39;a&#39;, class_=&#39;_3cb8&#39;)
  people_who_liked_page = []
  for name in names:
    people_who_liked_page.append(name.text)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the above code we assume that 15 page scrolls will show all the names of the people who follow the page, but you can increase it depending on the amount of people who follow your page.&lt;/p&gt;
&lt;h2 id=&#34;determine-the-winner&#34;&gt;Determine the winner&lt;/h2&gt;
&lt;p&gt;We now have three lists:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;People who liked the page&lt;/li&gt;
&lt;li&gt;People who liked the post&lt;/li&gt;
&lt;li&gt;People who shared the post&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We need to create a new list that has all the names of the people who appear in all three of the above lists:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eligible_to_win = []
for name in list_A:
  if name in list_B and name in list_C:
    eligible_to_win.append(name)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last thing to do is to select a winner randomly:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;winner = random.choice(eligible)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also select more than one winner:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;winners = random.sample(items, n)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where &lt;code&gt;n&lt;/code&gt; is the amount of winners you want to select.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This code will ensure that you can select a winner to the promotional post in only a few minutes, rather than doing it manually.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Web scraping for daily COVID-19 stats</title>
      <link>/project/web-scrape-coronavirus/</link>
      <pubDate>Sat, 28 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/project/web-scrape-coronavirus/</guid>
      <description>&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#what-is-web-scraping&#34;&gt;What is web scraping?&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#the-data-source&#34;&gt;The data source&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#coding-the-web-scraper&#34;&gt;Coding the web scraper&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#get-the-html-data&#34;&gt;Get the HTML data&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#what-is-beautifulsoup&#34;&gt;What is BeautifulSoup&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#installing-beautifulsoup&#34;&gt;Installing BeautifulSoup&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#extracting-the-data&#34;&gt;Extracting the data&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#find-table-id&#34;&gt;Find table ID&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#cleaning-up-the-scraped-data&#34;&gt;Cleaning up the scraped data&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#creating-a-dict-variable&#34;&gt;Creating a &lt;code&gt;dict&lt;/code&gt; variable&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#compiling-the-tweet&#34;&gt;Compiling the tweet&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#growth-factor&#34;&gt;Growth factor&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#getting-stats-for-the-tweet&#34;&gt;Getting stats for the tweet&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#constructing-the-tweet&#34;&gt;Constructing the tweet&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;As part of my aim to learn Python, I decided to teach myself by completing a bunch of projects created in Python. I started off by creating a 
&lt;a href=&#34;https://www.adriaansblog.com/project/twitter-bot-project/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Twitter bot&lt;/a&gt;, and now I want to expand it to web scraping daily stats of a website and tweeting about it.
I am specifically interested in the daily stats of the COVID-19 virus (Coronavirus) and what the daily new cases are as well as the global growth factor. The idea to look at the daily stats of the Coronavirus was sparked after watching a video by 
&lt;a href=&#34;https://www.youtube.com/watch?v=Kas0tIxDvrg&amp;amp;t&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3Blue1Brown&lt;/a&gt; where he discusses exponential growth of epidemics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Right! Let&amp;rsquo;s get started!&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-web-scraping&#34;&gt;What is web scraping?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Web scraping&lt;/strong&gt;, &lt;strong&gt;web harvesting&lt;/strong&gt;, or &lt;strong&gt;web data extraction&lt;/strong&gt; is used for extracting all kinds of data from websites. Web scraping can be done manually by the user, but web scraping typically includes automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the internet, typically into a database or spreadsheet, for later retrieval or analysis.&lt;/p&gt;
&lt;h2 id=&#34;the-data-source&#34;&gt;The data source&lt;/h2&gt;
&lt;p&gt;We are interested in the data contained in a table at 
&lt;a href=&#34;https://www.worldometers.info/coronavirus/#countries&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Worldometer&amp;rsquo;s&lt;/a&gt; website, where it lists all the countries together with their current reported coronavirus cases, new cases for the day, total deaths, new deaths for the day, etc. The idea is to get these daily figures, calculate the global growth factor and create a tweet that can be tweeted daily reporting the stats of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;United Kingdom and&lt;/li&gt;
&lt;li&gt;South Africa.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;coding-the-web-scraper&#34;&gt;Coding the web scraper&lt;/h2&gt;
&lt;h3 id=&#34;get-the-html-data&#34;&gt;Get the HTML data&lt;/h3&gt;
&lt;p&gt;First thing you need to do is to get the HTML data of the site you are interested in, into your Python script. We can do this using the Python library, &lt;code&gt;requests&lt;/code&gt;. You can install it using&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install requests
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once it is installed you can import it to your Python script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import requests

URL = &#39;https://www.worldometers.info/coronavirus/#countries&#39;
page = requests(get.URL)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code retrieves the HTML data that the server sends back and stores that data in a Python object.&lt;/p&gt;
&lt;p&gt;We have scraped some HTML from this webpage, but when you look at it, it just seems like a huge mess. There are tons of HTML elements and thousands of attributes scattered around. We can now parse this lengthy code response with &lt;strong&gt;Beautiful Soup&lt;/strong&gt; to make it more accessible and pick out the data that we are interested in.&lt;/p&gt;
&lt;h2 id=&#34;what-is-beautifulsoup&#34;&gt;What is BeautifulSoup&lt;/h2&gt;
&lt;p&gt;Beautiful Soup is a Python library used for pulling data out of HTML and XML files. It  provides ways of navigating, searching, and modifying the parse tree of a website. It can save programmers hours or days of work when gatering data.&lt;/p&gt;
&lt;h3 id=&#34;installing-beautifulsoup&#34;&gt;Installing BeautifulSoup&lt;/h3&gt;
&lt;p&gt;If you have not done so already, you need to install &lt;code&gt;BeautifulSoup&lt;/code&gt; which is the Python library that you will use to scrape data from the  webpage. You can install it using the command prompt:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install beautifulsoup4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once that is done, we can start using it in our Python script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from bs4 import BeautifulSoup

soup = BeautifulSoup(page.content, &#39;html.parser
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;extracting-the-data&#34;&gt;Extracting the data&lt;/h2&gt;
&lt;h3 id=&#34;find-table-id&#34;&gt;Find table ID&lt;/h3&gt;
&lt;p&gt;The Beautiful Soup object has been created in our Python script and the HTML data of the website has been scraped off of the page. Next we need to get the data that we are interested in, out of the HTML code. We first find the &lt;code&gt;id attribute&lt;/code&gt; of the table by using the &lt;strong&gt;inspect&lt;/strong&gt; fuctionality of the Chrome web browser. You right-click anywhere on the webpage and at the bottom of the dropdown list that appears, you select &lt;em&gt;inspect&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The ID of the table is &lt;code&gt;main_table_countries_today&lt;/code&gt;. We can use this to focus only on the table in the scraped HTML code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;results = soup.find(id=&#39;main_table_countries_today&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;With a website like this, it is possible that the structure of the website can change in the future, and this can include changing the &lt;code&gt;id attribute&lt;/code&gt; of the table which can cause an error in your code. You will just have to go back to the webpage and update your python code with the new table ID.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;cleaning-up-the-scraped-data&#34;&gt;Cleaning up the scraped data&lt;/h3&gt;
&lt;p&gt;If we go and print out the data contained in &lt;code&gt;results&lt;/code&gt;, we get:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;
&amp;lt;tr style=&amp;quot;&amp;quot;&amp;gt;
&amp;lt;td style=&amp;quot;font-weight: bold; font-size:15px; text-align:left;&amp;quot;&amp;gt;&amp;lt;a class=&amp;quot;mt_a&amp;quot; href=&amp;quot;country/uk/&amp;quot;&amp;gt;UK&amp;lt;/a&amp;gt;&amp;lt;/td&amp;gt;
&amp;lt;td style=&amp;quot;font-weight: bold; text-align:right&amp;quot;&amp;gt;14,543&amp;lt;/td&amp;gt;
&amp;lt;td style=&amp;quot;font-weight: bold; text-align:right;&amp;quot;&amp;gt;&amp;lt;/td&amp;gt;
&amp;lt;td style=&amp;quot;font-weight: bold; text-align:right;&amp;quot;&amp;gt;759 &amp;lt;/td&amp;gt;
&amp;lt;td style=&amp;quot;font-weight: bold; text-align:right;&amp;quot;&amp;gt;&amp;lt;/td&amp;gt;
&amp;lt;td style=&amp;quot;font-weight: bold; text-align:right&amp;quot;&amp;gt;135&amp;lt;/td&amp;gt;
&amp;lt;td style=&amp;quot;text-align:right;font-weight:bold;&amp;quot;&amp;gt;13,649&amp;lt;/td&amp;gt;
&amp;lt;td style=&amp;quot;font-weight: bold; text-align:right&amp;quot;&amp;gt;163&amp;lt;/td&amp;gt;
&amp;lt;td style=&amp;quot;font-weight: bold; text-align:right&amp;quot;&amp;gt;214&amp;lt;/td&amp;gt;
&amp;lt;td style=&amp;quot;font-weight: bold; text-align:right&amp;quot;&amp;gt;11&amp;lt;/td&amp;gt;
&amp;lt;td style=&amp;quot;text-align:right;font-size:13px;&amp;quot;&amp;gt;
Jan 30 &amp;lt;/td&amp;gt;
&amp;lt;/tr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data is the entry for the &lt;strong&gt;United Kingdom&lt;/strong&gt;, but there are still a lot of HTML code that we do not want. All the data entries of the table for the given country is wrapped in the HTML element &lt;code&gt;&amp;lt;td ... &amp;lt;\td&amp;gt;&lt;/code&gt;. We can use that knowledge to further clean up the scraped data:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;content = results.find_all(&#39;td&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we print out the data contained in &lt;code&gt;content&lt;/code&gt; we get:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;&amp;lt;td style=&amp;quot;font-weight: bold; font-size:15px; text-align:left;&amp;quot;&amp;gt;&amp;lt;a class=&amp;quot;mt_a&amp;quot; href=&amp;quot;country/uk/&amp;quot;&amp;gt;UK&amp;lt;/a&amp;gt;&amp;lt;/td&amp;gt;, &amp;lt;td style=&amp;quot;font-weight: bold; text-align:right&amp;quot;&amp;gt;14,543&amp;lt;/td&amp;gt;, &amp;lt;td style=&amp;quot;font-weight: bold; text-align:right;&amp;quot;&amp;gt;&amp;lt;/td&amp;gt;, &amp;lt;td style=&amp;quot;font-weight: bold; text-align:right;&amp;quot;&amp;gt;759 &amp;lt;/td&amp;gt;, &amp;lt;td style=&amp;quot;font-weight: bold; text-align:right;&amp;quot;&amp;gt;&amp;lt;/td&amp;gt;, &amp;lt;td style=&amp;quot;font-weight: bold; text-align:right&amp;quot;&amp;gt;135&amp;lt;/td&amp;gt;, &amp;lt;td style=&amp;quot;text-align:right;font-weight:bold;&amp;quot;&amp;gt;13,649&amp;lt;/td&amp;gt;, &amp;lt;td style=&amp;quot;font-weight: bold; text-align:right&amp;quot;&amp;gt;163&amp;lt;/td&amp;gt;, &amp;lt;td style=&amp;quot;font-weight: bold; text-align:right&amp;quot;&amp;gt;214&amp;lt;/td&amp;gt;, &amp;lt;td style=&amp;quot;font-weight: bold; text-align:right&amp;quot;&amp;gt;11&amp;lt;/td&amp;gt;, &amp;lt;td style=&amp;quot;text-align:right;font-size:13px;&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is still every chaotic. Luckily all the data that we need, it text and can be extracted from the above as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for data in content:
  print(data.text.strip())
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will contain the following data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;UK
14,543

759

135
13,649
163
214
11
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each line above is a column entry for the &lt;strong&gt;United Kingdom&lt;/strong&gt;. Next, this data needs to be entered into a dictionary so that we can use it to contruct a tweet.&lt;/p&gt;
&lt;h3 id=&#34;creating-a-dict-variable&#34;&gt;Creating a &lt;code&gt;dict&lt;/code&gt; variable&lt;/h3&gt;
&lt;h4 id=&#34;creating-seperate-lists&#34;&gt;Creating seperate lists&lt;/h4&gt;
&lt;p&gt;Before we can create a tweet reporting on the daily stats, we need to save the scraped data in some form that can be used effectively. For this project, all the data will be safed in a Python dictionary. To achieve this we will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Save each column in a list and&lt;/li&gt;
&lt;li&gt;Create a dictionary with all the populated lists.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, we initialise empty lists for each column:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;countries = []
total_cases = []
new_cases = []
total_deaths = []
new_deaths = []
total_recovered = []
active_cases = []
critical = []
total_per_mil_pop = []
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we iterate through the &lt;code&gt;content&lt;/code&gt; variable and place each corresponding entry into the correct list. There are 10 columns and as such a new country&amp;rsquo;s data is shown after every 10 iterations:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;i = 1
for data in content:
    if i%10 == 1:
        countries.append(data.text.strip())
    if i%10 == 2:
        total_cases.append(data.text.strip())
    if i%10 == 3:
        new_cases.append(data.text.strip())
    if i%10 == 4:
        total_deaths.append(data.text.strip())
    if i%10 == 5:
        new_deaths.append(data.text.strip())
    if i%10 == 6:
        total_recovered.append(data.text.strip())
    if i%10 == 7:
        active_cases.append(data.text.strip())
    if i%10 == 8:
        critical.append(data.text.strip())
    if i%10 == 0:
        total_per_mil_pop.append(data.text.strip())
    i += 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we assume the first column on the left (&lt;em&gt;Country&lt;/em&gt;) can be numbered as 1, then the mathematical operater &lt;code&gt;%10&lt;/code&gt; returns the modulus which corresponds to each column. This can then be used to ensure the correct data is appended to the correct list.&lt;/p&gt;
&lt;h4 id=&#34;combining-lists-into-a-dictionary&#34;&gt;Combining lists into a dictionary&lt;/h4&gt;
&lt;p&gt;After all the lists have been populated with the data scraped from the webpage, we can combine it into a dictionary:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;covid19_table = {
    &amp;quot;columns&amp;quot;: column_names,
    &amp;quot;country&amp;quot;: countries,
    &amp;quot;total_cases&amp;quot;: total_cases,
    &amp;quot;new_cases&amp;quot;: new_cases,
    &amp;quot;total_deaths&amp;quot;: total_deaths,
    &amp;quot;new_deaths&amp;quot;: new_deaths,
    &amp;quot;total_recovered&amp;quot;: total_recovered,
    &amp;quot;active_cases&amp;quot;: active_cases,
    &amp;quot;critical&amp;quot;: critical,
    &amp;quot;total_1M_ pop&amp;quot;: total_per_mil_pop}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;column_names&lt;/code&gt; have been generated seperately:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;column_names = [&amp;quot;Country&amp;quot;, 
    &amp;quot;Total Cases&amp;quot;, 
    &amp;quot;New Cases&amp;quot;, 
    &amp;quot;Total Deaths&amp;quot;, 
    &amp;quot;New Deaths&amp;quot;, 
    &amp;quot;Total Recovered&amp;quot;, 
    &amp;quot;Active Cases&amp;quot;, 
    &amp;quot;Serious/Critical&amp;quot;, 
    &amp;quot;Total Cases/1M pop&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are now ready to start using this data to contruct a tweet that will be sent out daily.&lt;/p&gt;
&lt;h2 id=&#34;compiling-the-tweet&#34;&gt;Compiling the tweet&lt;/h2&gt;
&lt;h3 id=&#34;growth-factor&#34;&gt;Growth factor&lt;/h3&gt;
&lt;p&gt;In order to calculate the growth factor of the coronavirus, the following equation can be used:&lt;/p&gt;
&lt;p&gt;$$Gf = \frac{N_i}{N_{i-1}}$$&lt;/p&gt;
&lt;p&gt;where $N_i$ is the amount of new cases for today and $N_{i-1}$ refers to the amount of new cases for the previous day.&lt;/p&gt;
&lt;p&gt;A .csv file will be used to store each day&amp;rsquo;s stats so that a new growth factor can be calculated each day:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;Date,Total_cases,New_cases,Growth_factor
2020-03-11,&amp;quot;126,007&amp;quot;,&amp;quot;7,059&amp;quot;,0.0
2020-03-12,&amp;quot;134,098&amp;quot;,&amp;quot;7,899&amp;quot;,1.12
2020-03-13,&amp;quot;145,336&amp;quot;,&amp;quot;10,759&amp;quot;,1.36
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A Python libary &lt;code&gt;pandas&lt;/code&gt; will be used to read from, and write to the .csv file. You can install &lt;code&gt;pandas&lt;/code&gt; using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;pip install pandas
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following was added to the python script to read the current content of the .csv file and put in a dictionary &lt;code&gt;new_table&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import pandas

df = pandas.read_csv(&#39;Total.csv&#39;, parse_dates = [&amp;quot;Date&amp;quot;], dayfirst = True)
new_table = df.to_dict()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The current date is added to the &lt;code&gt;new_table&lt;/code&gt; dictionary as it is the first entry required for the .csv file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;today = str(date.today())
new_table[&amp;quot;Date&amp;quot;][len(new_table[&amp;quot;Date&amp;quot;])] = today
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we calculate the growth factor. We first search for the position in the &lt;em&gt;country&lt;/em&gt; label of our &lt;code&gt;covid19_table&lt;/code&gt; dictionary for the total numbers for the whole world for the current day. This is under the *country * entry &lt;em&gt;Total:&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;search_position = covid19_table[&amp;quot;country&amp;quot;].index(&amp;quot;Total:&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we retrieve yesterday&amp;rsquo;s data from the &lt;code&gt;new_table&lt;/code&gt; dictionary which was created from the .csv file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;growth_yesterday = new_table[&amp;quot;New_cases&amp;quot;][len(new_table[&amp;quot;New_cases&amp;quot;])-1]
if type(growth_yesterday) == str:
        growth_yesterday = new_table[&amp;quot;New_cases&amp;quot;][len(new_table[&amp;quot;New_cases&amp;quot;])-1].replace(&#39;,&#39;,&#39;&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The amount of new cases globally is retrieved from the &lt;code&gt;covid19_table&lt;/code&gt; that we created from our scraped data using the &lt;code&gt;search_position&lt;/code&gt; which indicates where the corresponding data is in the dictionary.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;growth_today = covid19_table[&amp;quot;new_cases&amp;quot;][search_position].replace(&#39;,&#39;,&#39;&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The growth factor can now be calculated:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Gf = round(float(growth_today)/float(growth_yesterday),2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data needed for the current day&amp;rsquo;s entry for the .csv file is then added to the &lt;code&gt;new_table&lt;/code&gt; dictionary:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;new_table[&amp;quot;Total_cases&amp;quot;][len(new_table[&amp;quot;Total_cases&amp;quot;])] = covid19_table[&amp;quot;total_cases&amp;quot;][search_position]
new_table[&amp;quot;New_cases&amp;quot;][len(new_table[&amp;quot;New_cases&amp;quot;])] = covid19_table[&amp;quot;new_cases&amp;quot;][search_position]
new_table[&amp;quot;Growth_factor&amp;quot;][len(new_table[&amp;quot;Growth_factor&amp;quot;])] = str(Gf)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lastly, we convert the &lt;code&gt;new_table&lt;/code&gt; dictionary back to a .csv file that can be used the next day again:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df = pandas.DataFrame.from_dict(new_table)
df.to_csv(&amp;quot;Total.csv&amp;quot;,index=False)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;getting-stats-for-the-tweet&#34;&gt;Getting stats for the tweet&lt;/h3&gt;
&lt;p&gt;We create a dictionary that can be returned when the method is called with all the necessary data required for the tweet:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;position_UK = covid19_table[&amp;quot;country&amp;quot;].index(&amp;quot;UK&amp;quot;)
position_RSA = covid19_table[&amp;quot;country&amp;quot;].index(&amp;quot;South Africa&amp;quot;)
new_UK = covid19_table[&amp;quot;new_cases&amp;quot;][position_UK]
new_RSA = covid19_table[&amp;quot;new_cases&amp;quot;][position_RSA]
new_total = covid19_table[&amp;quot;new_cases&amp;quot;][search_position].replace(&#39;,&#39;,&#39;&#39;)
total_UK = covid19_table[&amp;quot;total_cases&amp;quot;][position_UK]
total_RSA = covid19_table[&amp;quot;total_cases&amp;quot;][position_RSA]
total_total =     covid19_table[&amp;quot;total_cases&amp;quot;][search_position].replace(&#39;,&#39;,&#39;&#39;)

tweet_data = {
    &amp;quot;UK&amp;quot;: {
    &amp;quot;Total&amp;quot;: total_UK,
    &amp;quot;New&amp;quot;: new_UK
    },
    &amp;quot;RSA&amp;quot;: {
    &amp;quot;Total&amp;quot;:total_RSA,
    &amp;quot;New&amp;quot;:new_RSA
    },
    &amp;quot;Total&amp;quot;: {
    &amp;quot;Total&amp;quot;: total_total,
    &amp;quot;New&amp;quot;: new_total
    },
    &amp;quot;Gf&amp;quot;: Gf
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;tweet_data&lt;/code&gt; dictionary can now be used to construct the tweet.&lt;/p&gt;
&lt;h3 id=&#34;constructing-the-tweet&#34;&gt;Constructing the tweet&lt;/h3&gt;
&lt;p&gt;The best way to create a multi-line tweet is to use a .txt file that can be fed to the twitter API. The content of the .txt file for the tweet was written together with the data in &lt;code&gt;tweet_data&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;with open(&#39;tweet.txt&#39;, &#39;w&#39;,encoding=&#39;utf-8&#39;) as f:
   f.write(&#39;#COVID19 stats &#39;+str(date.today())+&#39;:\n\
   \nTotal cases for:\nUK: &#39;+str(tweet_data[&amp;quot;UK&amp;quot;][&amp;quot;Total&amp;quot;])+&#39; (&#39;+str(tweet_data[&amp;quot;UK&amp;quot;][&amp;quot;New&amp;quot;])+&#39;)&#39;+&#39;\
   \nRSA: &#39;+str(tweet_data[&amp;quot;RSA&amp;quot;][&amp;quot;Total&amp;quot;])+&#39; (&#39;+str(tweet_data[&amp;quot;RSA&amp;quot;][&amp;quot;New&amp;quot;])+&#39;)&#39;+&#39;\
   \nOverall: &#39;+str(tweet_data[&amp;quot;Total&amp;quot;][&amp;quot;Total&amp;quot;])+&#39; (+&#39;+str(tweet_data[&amp;quot;Total&amp;quot;][&amp;quot;New&amp;quot;])+&#39;)&#39;+&#39;\
   \n\nGrowth factor: &#39;+str(tweet_data[&amp;quot;Gf&amp;quot;])+&#39;\
   \n\n#CoronaVirusSA \n#CoronaVirusUK&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last thing left is to tweet it!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;with open(&#39;tweet.txt&#39;,&#39;r&#39;) as f:
   api.update_status(f.read())
&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;    
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/COVID19?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#COVID19&lt;/a&gt; stats 2020-03-27:&lt;br&gt; &lt;br&gt;Total cases for:&lt;br&gt;UK: 14,543 (+2,885) &lt;br&gt;RSA: 1,170 (+243) &lt;br&gt;Overall: 590628 (+58818) &lt;br&gt;&lt;br&gt;Growth factor: 1.0 &lt;a href=&#34;https://twitter.com/hashtag/CoronaVirusSA?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CoronaVirusSA&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/CoronaVirusUK?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CoronaVirusUK&lt;/a&gt;&lt;/p&gt;&amp;mdash; COVID-19 stats tracker (@nog_nuus) &lt;a href=&#34;https://twitter.com/nog_nuus/status/1243658693239017484?ref_src=twsrc%5Etfw&#34;&gt;March 27, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;</description>
    </item>
    
    <item>
      <title>Create a Twitter bot</title>
      <link>/project/twitter-bot-project/</link>
      <pubDate>Thu, 12 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/project/twitter-bot-project/</guid>
      <description>&lt;p&gt;As part of my aim to learn Python, I decided to teach myself by completing a bunch of projects created in Python, and a Twitter bot is my first project!&lt;/p&gt;
&lt;p&gt;The purpose of this article is two-fold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Helping you to create a Twitter bot of your own.&lt;/li&gt;
&lt;li&gt;Record the process for when I return to this project in the future.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Right! Let&amp;rsquo;s get started!&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;some-background-watching&#34;&gt;Some background watching&lt;/h2&gt;
&lt;p&gt;I came across a video by CS Dojo 
&lt;a href=&#34;https://www.youtube.com/watch?v=W0wWwglE1Vc&amp;amp;t&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How To Create A Twitter Bot With Python&lt;/a&gt;. Do check it out!
I also created a video showing the process for those that rather prefer watching how it is done vs. reading about it.&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/28K8uy8SP6s&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;div style=&#34;text-align: left;&#34;&gt;
&lt;h2 id=&#34;getting-started-with-twitter-api&#34;&gt;Getting started with Twitter API&lt;/h2&gt;
&lt;p&gt;The first thing you need to do is create an account at 
&lt;a href=&#34;https://developer.twitter.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Twitter Developer&lt;/a&gt;. Make sure you are logged into the Twitter account that you want to use to create the Twitter bot. Create your account and add an app that will generate your authorisation keys that you need to connect to the Twitter API.
These keys will be used in the Python script to connect to the API.&lt;/p&gt;
&lt;h2 id=&#34;connect-to-the-twitter-api-with-python&#34;&gt;Connect to the Twitter API with Python&lt;/h2&gt;
&lt;p&gt;The first thing you need to do is to install &lt;code&gt;tweepy&lt;/code&gt; which is the Python library that you will use to connect to the Twitter API. You can install is using the command prompt:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install tweepy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once that is done, you can get started with setting up your &lt;code&gt;twitter_bot.py&lt;/code&gt; script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import tweepy

CONSUMER_KEY = &#39;YOUR_CONSUMER_KEY&#39;
CONSUMER_SECRET = &#39;YOUR_CONSUMER_SECRET_KEY&#39;
ACCESS_KEY = &#39;YOUR_ACCESS_KEY&#39;
ACCESS_SECRET = &#39;YOUR_ACCESS_SECRET_KEY&#39;

auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)
auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)
api = tweepy.API(auth, wait_on_rate_limit=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can copy the four key values from your created app in your Twitter Developer account.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you plan to commit your code to an online repository, do not add your access keys to your code directly, as others will be able to see it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The last three lines of the code sets up the API so that you can use it for all kinds of &lt;em&gt;cool&lt;/em&gt; stuff. Make sure you go have a look at the 
&lt;a href=&#34;http://docs.tweepy.org/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tweepy documentation&lt;/a&gt; to find out what the &lt;code&gt;tweepy&lt;/code&gt; library can do.&lt;/p&gt;
&lt;h2 id=&#34;fav-and-retweet&#34;&gt;Fav and retweet!&lt;/h2&gt;
&lt;p&gt;For this project, I want to create a bot that will &lt;em&gt;favourite&lt;/em&gt; a tweet and &lt;em&gt;retweet&lt;/em&gt; it when your twitter account is mentioned.&lt;/p&gt;
&lt;h3 id=&#34;scan-for-any-tweets-mentioning-the-account&#34;&gt;Scan for any tweets mentioning the account&lt;/h3&gt;
&lt;p&gt;First we need to collect all the tweets that mention the account. &lt;code&gt;Tweepy&lt;/code&gt; enables you to collect the 20 latest tweets mentioning your account.&lt;/p&gt;
&lt;p&gt;It is necessary to specify the last tweet ID that you interacted with to ensure that you don&amp;rsquo;t retweet &lt;em&gt;or&lt;/em&gt; favourite any tweet you already have.&lt;/p&gt;
&lt;p&gt;We can store the ID of the last tweet that we enteracted with in a .txt file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def retrieve_last_seen_id(file_name):
  f_read = open(file_name, &#39;r&#39;)
  last_seen_id = int(f_read.read().strip())
  f_read.close()
  return last_seen_id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function opens up the textfile and reads the tweet ID and returns it as an integer in the variable &lt;code&gt;last_seen_id&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Next we retrieve all the tweets mentioning your twitter account after the last tweet ID specified in your textfile.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mentions = api.mentions_timeline(last_seen_id, tweet_mode = &#39;extended&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We loop through all the tweet IDs in the &lt;code&gt;mentions&lt;/code&gt; variable. The loop starts at the end of the list, which will be the oldest tweet that we haven&amp;rsquo;t interact with yet.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for mention in reversed(mentions):
    if not mention:
        return
    last_fav_tweet = mention.id
    store_last_seen_id(last_fav_tweet,FILE_NAME_FAV)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The tweet ID of the last interacted tweet is updated in the text file, using the function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def store_last_seen_id(last_seen_id,file_name):
  f_write = open(file_name, &#39;w&#39;)
  f_write.write(str(last_seen_id))
  f_write.close()
  return
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The tweet ID stored in the &lt;code&gt;mention.id&lt;/code&gt; is then &lt;em&gt;favourited&lt;/em&gt; and &lt;em&gt;retweeted&lt;/em&gt; with the commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;api.create_favorite(mention.id)
api.retweet(mention.id)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;deploying-the-bot&#34;&gt;Deploying the bot&lt;/h2&gt;
&lt;p&gt;Now that you have set up the bot it needs to run continuously to check for tweets mentioning your account. This can be done by putting the function in an infinite loop:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;while True:
  fav_tweets()
  time.sleep(15)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code &lt;code&gt;time.sleep()&lt;/code&gt; pauses the &lt;code&gt;while&lt;/code&gt; loop for a period specified here as 15 seconds. Make sure to add&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import time
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to your script to enable this functionality.&lt;/p&gt;
&lt;h3 id=&#34;using-heroku&#34;&gt;Using Heroku&lt;/h3&gt;
&lt;p&gt;The problem with running the bot locally on your computer is that your command prompt window will be occupied running the bot, so you won&amp;rsquo;t be able to use it.&lt;/p&gt;
&lt;p&gt;The best solution is to deploy it on a server, and 
&lt;a href=&#34;https://www.heroku.com/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Heroku&lt;/a&gt; is a free service for just that purpose!
The best place to start is to follow Heroku&amp;rsquo;s 
&lt;a href=&#34;https://devcenter.heroku.com/articles/getting-started-with-python&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;step-by-step guide for deploying using Python&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You will need to sign up for an account and then install the &lt;em&gt;Heroku CLI&lt;/em&gt; to your computer. You can either link your Heroku account to your Github repository where your bot has been uploaded, or you can upload it to a &lt;em&gt;Heroku repository&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We will use the &lt;em&gt;Heroku repository&lt;/em&gt;. Once you have installed the &lt;em&gt;Heroku CLI&lt;/em&gt; to your computer, login using the command prompt:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ heroku login
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;create-a-heroku-app&#34;&gt;Create a Heroku app&lt;/h3&gt;
&lt;p&gt;The next step is to initiate a git repository on your local machine using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git init
$ cd the-name-of-your-bot
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;You can also clone the &lt;code&gt;getting-started-with-python&lt;/code&gt; repository that Heroku provides. It has all the additional documents already created that you need. All you need to do is copy those files over to your project&amp;rsquo;s folder.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After a git repository has been initialised, you need to commit all your changes and then create an app on Heroku, which prepares Heroku to receive your source code:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;$ git add .
$ git commit -m &amp;quot;initial commit&amp;quot;

$ heroku create

$ git push heroku master
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;last-few-things&#34;&gt;Last few things&lt;/h3&gt;
&lt;p&gt;So the last problem is that you need to get your API authorisation keys to the Heroku repository without making it public knowledge.&lt;/p&gt;
&lt;p&gt;Before you push your repository to Heroku, make the following changes to your code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import os
from os import environ

CONSUMER_KEY = environ[&#39;YOUR_CONSUMER_KEY&#39;]
CONSUMER_SECRET = environ[&#39;YOUR_CONSUMER_SECRET&#39;]
ACCESS_KEY = environ[&#39;YOUR_ACCESS_KEY&#39;]
ACCESS_SECRET = environ[&#39;YOUR_ACCESS_SECRET&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code makes sure that you do not need to commit your Twitter API keys. After you have edited your code, you need to add your API keys to your Heroku account by going to your Heroku app, going to settings and editing the &lt;em&gt;Config Vars&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Also, there are a few more files that you need to upload to Heroku before it will be functional. This include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Procfile&lt;/li&gt;
&lt;li&gt;Requirements.txt&lt;/li&gt;
&lt;li&gt;Runtime.txt&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;This is only necessary if you haven&amp;rsquo;t already copied them over from the repository &lt;code&gt;getting-started-with-python&lt;/code&gt; that you cloned.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;procfile&#34;&gt;Procfile&lt;/h3&gt;
&lt;p&gt;Heroku apps include a Procfile that specifies the commands that are executed by the app on startup. You need to use a Procfile to declare that this is a worker:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;worker: python your_bot_name.py
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;requirementstxt&#34;&gt;Requirements.txt&lt;/h3&gt;
&lt;p&gt;The requirements file lists the versions of all the programs that your bot will use:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;certifi==2019.11.28
chardet==3.0.4
idna==2.9
oauthlib==3.1.0
PySocks==1.7.1
requests==2.23.0
requests-oauthlib==1.3.0
six==1.14.0
tweepy==3.6.0
urllib3==1.25.8
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;runtime-file&#34;&gt;Runtime file&lt;/h3&gt;
&lt;p&gt;This file specifies the version of Python that Heroku needs to use. At the time of writing this, Tweepy does not support Python 3.7, so you need to specify an older version.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python-3.6.9
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>JSAE/SAE conference in Kyoto, Japan</title>
      <link>/post/jsae_conference/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/jsae_conference/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;NO&lt;sub&gt;x&lt;/sub&gt; emissions have become a health concern in cities with calls to reduce and ban vehicles with CI engines from entering the city. As such, our aim is to reduce NO&lt;sub&gt;x&lt;/sub&gt; emissions being produced by the CI engine, and Low Temperature Combustion (LTC) is seen as a viable option.&lt;/p&gt;
&lt;p&gt;LTC is a broad term used generally for combustion techniques where the overall peak combustion temperature is reduced. This is beneficial as it reduces the formation of NO&lt;sub&gt;x&lt;/sub&gt; exhaust gasses. LTC techniques include HCCI, PCCI and RCCI. Although NO&lt;sub&gt;x&lt;/sub&gt; emissions is reduced as a result of lower temperatures, other emissions such as CO emissions and HC emissions can increase due to incomplete combustion.&lt;/p&gt;
&lt;p&gt;There is thus a balance that needs to be optimised to ensure an overall reduction of all emissions. This research focussed on achieving emissions reduction by optimising EGR and the engine’s fuel delivery.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/JSAE_conference/index_files/JSAE-PFL2019-effects-of-temperature-and-homogeneity.jpg&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this research we looked at four parameters that can be used to achieve LTC and ultimately reduce NO&lt;sub&gt;x&lt;/sub&gt; and CO emissions. NO&lt;sub&gt;x&lt;/sub&gt; emissions is reduced by reducing the combustion temperature and CO emissions are reduced by increasing the homogeneity of the air fuel mixture. The table shown in the slide shows the effects on the combustion temperature and the homogeneity of the air fuel mixture as reported in the literature.&lt;/p&gt;
&lt;p&gt;If we increase pilot injection duration, then the homogeneity of the charge increases as more fuel is being introduced in the pilot injection and thus more of the fuel can mix with the air before combustion occurs. Premixed combustion also increases as a result of this, ultimately increasing the combustion temperature.&lt;/p&gt;
&lt;p&gt;If we advance the pilot injection start of injection (SOI), then the homogeneity of the charge is increased, as there is more time for the fuel to mix with the air before combustion occurs. Increased homogeneity also increases the premixed combustion, which increases the combustion temperature.&lt;/p&gt;
&lt;p&gt;If we advance the main injection SOI, then the time for the fuel to mix with the air is decreased, which reduces the homogeneity of the charge as well as the combustion temperature.&lt;/p&gt;
&lt;p&gt;If we increase the Exhaust gas recirculation (EGR) percentage, then the homogeneity of the charge is increased, as more EGR increases the ignition delay and gives the fuel more time to mix with the air. It also reduces the combustion temperature as more inert gasses are introduced into the inlet charge, which absorbs a lot of the heat.&lt;/p&gt;
&lt;p&gt;From this table, it can be seen that the four parameters have different effects on combustion temperature and charge homogeneity. It is thus necessary to determine which parameter has a significant effect on emissions formation and which parameter has a lesser effect.&lt;/p&gt;
&lt;p&gt;The Design of Experiment (DoE) statistical tool was used to determine the effect of each parameter on the formation of engine emissions and if it is significant or not. A DoE was also used to determine the impact of each parameter as well as determine an optimised point that resulted in overall reduced emissions.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/JSAE_conference/index_files/JSAE-PFL2019-transient-vs-steady-state.jpg&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Next we need to consider the drive cycle that will be used in the simulation. When we look at how past research has generated experimental emissions data, the majority of research found have used steady state engine operating points in their test methodology. The results from steady state experimentation cannot accurately represent real life scenarios. A transient drive cycle is needed to generate results that are comparable to real life. The WLTP was used in this research. It replaced the NEDC that has been used in the past to test the new vehicle entering the market.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/JSAE_conference/index_files/JSAE-PFL2019-transient-vs-steady-state-WLTP.jpg&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I have created this figure to further illustrate the benefits of using the WLTP for real world emissions investigation. The graph shows the WLTP, in grey circles, as a function of engine speed and BMEP. The red crosses indicate the steady state points used by past research to investigate engine emissions. When looking at the graph, clear gaps are evident in the engine operating map that is not covered by the research considered. The use of a transient drive cycle is thus appropriate if the results needed to be comparable to a real world scenario.&lt;/p&gt;
&lt;div id=&#34;methodology&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Methodology&lt;/h2&gt;
&lt;p&gt;An engine simulation was used to investigate the effects of varying the different engine operating parameters on engine emissions. A 2.4 L turbocharged CI engine was simulated. The simulation’s combustion model was validated using in-cylinder pressure data and emissions data was used to validate its emissions models.&lt;/p&gt;
&lt;p&gt;The Wiebe combustion model was used in this research. Linear regression models was generated for the start of combustion crank angle degree (CAD), premixed fuel mass fraction burned and Wiebe exponent by using the cylinder pressure data. This is necessary as we are simulating a transient drive cycle as well as changing engine parameters that influence combustion.
The emission models were validated using exhaust gas analyser experimental data. The engine simulation can only simulate CO emissions and NO&lt;sub&gt;x&lt;/sub&gt; emissions.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/JSAE_conference/index_files/JSAE-PFL2019-cylinder-pressure-graphs-validation.jpg&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;After the models were calibrated, it was compared to experimental data to check its accuracy. Here two cylinder pressure graphs are shown; one at 25% load and 1500rpm and the other at 75% load and 3000rpm. The experimental data is shown in a solid line and the simulated model is shown in dashed lines. As can be seen, the simulated results correlate well with the experimental data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/JSAE_conference/index_files/JSAE-PFL2019-emission-graphs-validation.jpg&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Same can be said of the simulated emissions. The simulated emission results for the CO emissions and NOx emissions correlate well with the experimental data. We thus have confidence in our simulation and can now move on to setting up the DoE.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/JSAE_conference/index_files/JSAE-PFL2019-DoE-setup-for-simulation.jpg&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When setting up the factorial design, a 2^4 factorial design was chosen as there are 4 parameters that will be investigated. These are EGR percentage, pilot injection duration and main and pilot injection SOI. The test engine is using an aftermarket ECU, which have operating maps loaded onto it by default. These operating maps are used as the starting point for the DoE. The EGR percentage map is in the form of an island with maximum EGR at approximately 2500 rpm and 10 % throttle position. Here is an example of an EGR map with 47% as the maximum percentage. The value as given by the DoE will always be the maximum value and the maps will be scaled according to the maximum value.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/JSAE_conference/index_files/JSAE-PFL2019-first-factorial-design.jpg&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Shown here is a table with the low and high values of the first factorial design.
The EGR percentage has a low and high value of 0 % and 10 %, pilot injection and main injection SOI is advanced by one CAD and retarded by 1 CAD. The pilot injection duration is decreased by 100 μs and increased by 100 μs. Similar tables were created for the second and third factorial designs based on the results from the previous factorial design.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/JSAE_conference/index_files/JSAE-PFL2019-generation-of-next-factorial-designs.jpg&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In order to determine the configuration that will reduce emissions the most, we opted to follow the path of greatest emission reduction using multiple factorial designs. After each factorial design, The desirability function was used to determine the best configuration of the parameters under investigation. This then was used to set up the next factorial design. This can be explained in the figure shown.&lt;/p&gt;
&lt;p&gt;The figure shows the three factorial designs for two parameters, pilot injection SOI and EGR percentage. As can be seen for the first factorial design, the EGR is varied from 0 % to 10 % and the pilot injection SOI is advanced and retarded by 1 CAD. Once the first factorial design is completed, the desirability function is used to determine which configuration reduces the emissions the most. In this case it is an EGR percentage of 10 % and by retarding the pilot injection SOI by 1 CAD. The low and high values of the second factorial design can now be determined with the use of the two equations shown on the slide.&lt;/p&gt;
&lt;p&gt;As a maximum desirability (D&lt;sub&gt;i&lt;/sub&gt;) is achieved at 10 % EGR, the second factorial design’s low value becomes 10 % and the high level value for the second factorial design becomes 25 %. For the pilot injection SOI, the second factorial design’s low value is set to retard the map by 1 CAD and the high values is set to retard the operating map by 4 CADs.&lt;/p&gt;
&lt;p&gt;Once the second factorial design is finished, the desirability function is used again to determine which configuration results in the reducing the emissions the most. This results in a EGR percentage of 25 % and retarding the pilot injection SOI by 2 CADs. As such the low and high values for the EGR percentage for the third factorial design is calculated as 25 % and 47.5%. The pilot injection SOI low and high values for the third factorial design stays at retarding the maps with 1 CAD and 4 CADs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;results-and-discussion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Results and discussion&lt;/h2&gt;
&lt;p&gt;Shown on this slide is the desirability function plot for the third factorial design that was simulated. As can be seen, by the third factorial design, the start of injection for the pilot and main injection and the injection duration of the pilot injection does not significantly influence the emissions. This can be seen by the almost horizontal lines of the graph.&lt;/p&gt;
&lt;p&gt;The EGR percentage has a significant effect on the NO&lt;sub&gt;x&lt;/sub&gt; emissions and CO emissions as the graph lines have a steep gradient. The desirability function plot at the top in the form of a half circle indicate that the maximum desirability value will be reached for an EGR percentage at approximately 36 %.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/JSAE_conference/index_files/JSAE-PFL2019-emissions-results.jpg&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When we put all the factorial designs’ results on one graph, we can get a better overall picture.
For the second factorial design, we optimised towards a maximum of CO emissions as per the Euro 4 limits. This resulted in a reduction of approximately 20% of NO&lt;sub&gt;x&lt;/sub&gt; when we use a maximum of 12% EGR.&lt;/p&gt;
&lt;p&gt;To further investigate LTC, for the third factorial design, we opted to continue to increase the EGR percentage to 47.5%. This resulted in a reduction in NO&lt;sub&gt;x&lt;/sub&gt; of 85% to 0.55g/km where the Euro 4 limit is 0.25g/km. The CO emissions greatly increased as a result of the EGR percentage increasing, to 22.58g/km.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/JSAE_conference/index_files/JSAE-PFL2019-check-for-LTC.jpg&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Next we wanted to see if we achieved LTC. This graph shows the peak temperature for combustion with no LTC techniques used as well as for the combustion temperature for the third factorial design. The difference in peak temperature between the two graphs is approximately 100 °K.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NO&lt;sub&gt;x&lt;/sub&gt; emissions were reduced by approximately 85% with an EGR percentage of 47.5 %, retarding the pilot injection and main injection SOI by 1 CAD and increasing the pilot injection duration by 200 μs.&lt;/li&gt;
&lt;li&gt;NO&lt;sub&gt;x&lt;/sub&gt; emissions reduced by approximately 20 % with the use of 12 % EGR without exceeding the Euro 4 CO emissions limit.&lt;/li&gt;
&lt;li&gt;Low temperature combustion was achieved&lt;/li&gt;
&lt;li&gt;The method of using DoE to minimise engine out emissions was successful&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Limitations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The sample size of the experimental data is modest. By using more experimental data, more robust regression models can be constructed.&lt;/li&gt;
&lt;li&gt;A blind transient comparison between simulation and experimental results would be beneficial and increase our confidence in our engine simulation.&lt;/li&gt;
&lt;li&gt;Following the path of greatest emission reduction, was successful, but it can result in finding a local minimum, where we want to determine the global minimum.&lt;/li&gt;
&lt;li&gt;The DoE can be improved by investigate the whole operating map of the engine to ensure that we will be able to determine the global minimum.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
